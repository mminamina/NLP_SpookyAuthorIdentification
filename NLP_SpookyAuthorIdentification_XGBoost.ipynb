{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spooky-author-identification/test.zip\n",
      "/kaggle/input/spooky-author-identification/train.zip\n",
      "/kaggle/input/spooky-author-identification/sample_submission.zip\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer, PorterStemmer\n",
    "import string\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import ensemble, metrics, model_selection, naive_bayes\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 3) (8392, 2)\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "train = pd.read_csv(\"/kaggle/input/spooky-author-identification/train.zip\")\n",
    "test = pd.read_csv(\"/kaggle/input/spooky-author-identification/test.zip\")\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt_srs = train['author'].value_counts()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Author Name', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words \n",
    "train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Number of unique words\n",
    "train[\"num_unique_words\"] = train[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# Number of characters\n",
    "train[\"num_chars\"] = train[\"text\"].apply(lambda x: len(str(x)))\n",
    "test[\"num_chars\"] = test[\"text\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Number of stopwords \n",
    "train[\"num_stopwords\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "test[\"num_stopwords\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "\n",
    "# Number of punctuations\n",
    "train[\"num_punctuations\"] =train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test[\"num_punctuations\"] =test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "# Number of title case words\n",
    "train[\"num_words_upper\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test[\"num_words_upper\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "# Number of title case words\n",
    "train[\"num_words_title\"] = train[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "test[\"num_words_title\"] = test[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "# Average length of the words\n",
    "train[\"mean_word_len\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author mapping\n",
    "author_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\n",
    "train_y = train['author'].map(author_mapping_dict)\n",
    "train_id = train['id'].values\n",
    "test_id = test['id'].values\n",
    "\n",
    "train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "test[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "train[\"mean_word_len\"] = train[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test[\"mean_word_len\"] = test[\"text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "cols_to_drop = ['id', 'text']\n",
    "train_X = train.drop(cols_to_drop+['author'], axis=1)\n",
    "test_X = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runMNB(train_X, train_y, test_X, test_y, test_X2):\n",
    "    model = naive_bayes.MultinomialNB()\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_test_y = model.predict_proba(test_X)\n",
    "    pred_test_y2 = model.predict_proba(test_X2)\n",
    "    return pred_test_y, pred_test_y2, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf vectorizer\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "full_tfidf = tfidf_vec.fit_transform(train['text'].values.tolist() + test['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD on word TFIDF\n",
    "n_comp = 20\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_obj.fit(full_tfidf)\n",
    "train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\n",
    "test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n",
    "    \n",
    "train_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "test_svd.columns = ['svd_word_'+str(i) for i in range(n_comp)]\n",
    "train = pd.concat([train, train_svd], axis=1)\n",
    "test = pd.concat([test, test_svd], axis=1)\n",
    "del full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer \n",
    "tfidf_vec = CountVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "tfidf_vec.fit(train['text'].values.tolist() + test['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  0.4530287297009889\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 3])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5.\n",
    "\n",
    "# add the predictions as new features #\n",
    "train[\"nb_cvec_eap\"] = pred_train[:,0]\n",
    "train[\"nb_cvec_hpl\"] = pred_train[:,1]\n",
    "train[\"nb_cvec_mws\"] = pred_train[:,2]\n",
    "test[\"nb_cvec_eap\"] = pred_full_test[:,0]\n",
    "test[\"nb_cvec_hpl\"] = pred_full_test[:,1]\n",
    "test[\"nb_cvec_mws\"] = pred_full_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cv score :  0.790415258947421\n"
     ]
    }
   ],
   "source": [
    "### Fit transform the tfidf vectorizer \n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='char')\n",
    "full_tfidf = tfidf_vec.fit_transform(train['text'].values.tolist() + test['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train['text'].values.tolist())\n",
    "test_tfidf = tfidf_vec.transform(test['text'].values.tolist())\n",
    "\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 3])\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_tfidf[dev_index], train_tfidf[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, model = runMNB(dev_X, dev_y, val_X, val_y, test_tfidf)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5.\n",
    "\n",
    "# add the predictions as new features #\n",
    "train[\"nb_tfidf_char_eap\"] = pred_train[:,0]\n",
    "train[\"nb_tfidf_char_hpl\"] = pred_train[:,1]\n",
    "train[\"nb_tfidf_char_mws\"] = pred_train[:,2]\n",
    "test[\"nb_tfidf_char_eap\"] = pred_full_test[:,0]\n",
    "test[\"nb_tfidf_char_hpl\"] = pred_full_test[:,1]\n",
    "test[\"nb_tfidf_char_mws\"] = pred_full_test[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comp = 20\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_obj.fit(full_tfidf)\n",
    "train_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\n",
    "test_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n",
    "    \n",
    "train_svd.columns = ['svd_char_'+str(i) for i in range(n_comp)]\n",
    "test_svd.columns = ['svd_char_'+str(i) for i in range(n_comp)]\n",
    "train = pd.concat([train, train_svd], axis=1)\n",
    "test = pd.concat([test, test_svd], axis=1)\n",
    "del full_tfidf, train_tfidf, test_tfidf, train_svd, test_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, seed_val=42, child=1, colsample=0.3):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 2\n",
    "    param['silent'] = 1\n",
    "    param['num_class'] = 3\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = child\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = colsample\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = 2200\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=200, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit = model.best_ntree_limit)\n",
    "    if test_X2 is not None:\n",
    "        xgtest2 = xgb.DMatrix(test_X2)\n",
    "        pred_test_y2 = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\n",
    "    return pred_test_y, pred_test_y2, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.01542\ttest-mlogloss:1.0172\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-mlogloss:0.468104\ttest-mlogloss:0.48921\n",
      "[40]\ttrain-mlogloss:0.38763\ttest-mlogloss:0.415603\n",
      "[60]\ttrain-mlogloss:0.363027\ttest-mlogloss:0.395252\n",
      "[80]\ttrain-mlogloss:0.34834\ttest-mlogloss:0.385614\n",
      "[100]\ttrain-mlogloss:0.337203\ttest-mlogloss:0.379241\n",
      "[120]\ttrain-mlogloss:0.328077\ttest-mlogloss:0.37435\n",
      "[140]\ttrain-mlogloss:0.320531\ttest-mlogloss:0.370939\n",
      "[160]\ttrain-mlogloss:0.313978\ttest-mlogloss:0.368358\n",
      "[180]\ttrain-mlogloss:0.308344\ttest-mlogloss:0.366516\n",
      "[200]\ttrain-mlogloss:0.303144\ttest-mlogloss:0.364425\n",
      "[220]\ttrain-mlogloss:0.298287\ttest-mlogloss:0.363482\n",
      "[240]\ttrain-mlogloss:0.293577\ttest-mlogloss:0.361852\n",
      "[260]\ttrain-mlogloss:0.289599\ttest-mlogloss:0.361295\n",
      "[280]\ttrain-mlogloss:0.286035\ttest-mlogloss:0.360481\n",
      "[300]\ttrain-mlogloss:0.282437\ttest-mlogloss:0.359414\n",
      "[320]\ttrain-mlogloss:0.279001\ttest-mlogloss:0.358873\n",
      "[340]\ttrain-mlogloss:0.275537\ttest-mlogloss:0.358423\n",
      "[360]\ttrain-mlogloss:0.272362\ttest-mlogloss:0.358266\n",
      "[380]\ttrain-mlogloss:0.269332\ttest-mlogloss:0.357885\n",
      "[400]\ttrain-mlogloss:0.266406\ttest-mlogloss:0.357538\n",
      "[420]\ttrain-mlogloss:0.263463\ttest-mlogloss:0.357689\n",
      "[440]\ttrain-mlogloss:0.260656\ttest-mlogloss:0.357477\n",
      "[460]\ttrain-mlogloss:0.257962\ttest-mlogloss:0.357095\n",
      "[480]\ttrain-mlogloss:0.255285\ttest-mlogloss:0.356861\n",
      "[500]\ttrain-mlogloss:0.252683\ttest-mlogloss:0.356848\n",
      "[520]\ttrain-mlogloss:0.250077\ttest-mlogloss:0.35685\n",
      "[540]\ttrain-mlogloss:0.247515\ttest-mlogloss:0.356731\n",
      "[560]\ttrain-mlogloss:0.244909\ttest-mlogloss:0.356939\n",
      "[580]\ttrain-mlogloss:0.242603\ttest-mlogloss:0.356886\n",
      "[600]\ttrain-mlogloss:0.24039\ttest-mlogloss:0.356939\n",
      "[620]\ttrain-mlogloss:0.238099\ttest-mlogloss:0.357093\n",
      "[640]\ttrain-mlogloss:0.23583\ttest-mlogloss:0.357136\n",
      "[660]\ttrain-mlogloss:0.233571\ttest-mlogloss:0.35737\n",
      "[680]\ttrain-mlogloss:0.231393\ttest-mlogloss:0.357188\n",
      "[700]\ttrain-mlogloss:0.229165\ttest-mlogloss:0.357149\n",
      "[720]\ttrain-mlogloss:0.226821\ttest-mlogloss:0.357285\n",
      "Stopping. Best iteration:\n",
      "[536]\ttrain-mlogloss:0.24804\ttest-mlogloss:0.356612\n",
      "\n",
      "[0]\ttrain-mlogloss:1.01608\ttest-mlogloss:1.0159\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-mlogloss:0.473574\ttest-mlogloss:0.47421\n",
      "[40]\ttrain-mlogloss:0.394018\ttest-mlogloss:0.395068\n",
      "[60]\ttrain-mlogloss:0.369408\ttest-mlogloss:0.373029\n",
      "[80]\ttrain-mlogloss:0.354831\ttest-mlogloss:0.361836\n",
      "[100]\ttrain-mlogloss:0.343542\ttest-mlogloss:0.354283\n",
      "[120]\ttrain-mlogloss:0.334786\ttest-mlogloss:0.348828\n",
      "[140]\ttrain-mlogloss:0.327472\ttest-mlogloss:0.34434\n",
      "[160]\ttrain-mlogloss:0.320968\ttest-mlogloss:0.341241\n",
      "[180]\ttrain-mlogloss:0.315216\ttest-mlogloss:0.3382\n",
      "[200]\ttrain-mlogloss:0.309815\ttest-mlogloss:0.336483\n",
      "[220]\ttrain-mlogloss:0.305162\ttest-mlogloss:0.334204\n",
      "[240]\ttrain-mlogloss:0.300757\ttest-mlogloss:0.332598\n",
      "[260]\ttrain-mlogloss:0.296676\ttest-mlogloss:0.331667\n",
      "[280]\ttrain-mlogloss:0.292687\ttest-mlogloss:0.330757\n",
      "[300]\ttrain-mlogloss:0.289296\ttest-mlogloss:0.329802\n",
      "[320]\ttrain-mlogloss:0.28578\ttest-mlogloss:0.329101\n",
      "[340]\ttrain-mlogloss:0.282374\ttest-mlogloss:0.328523\n",
      "[360]\ttrain-mlogloss:0.279128\ttest-mlogloss:0.327546\n",
      "[380]\ttrain-mlogloss:0.275967\ttest-mlogloss:0.326896\n",
      "[400]\ttrain-mlogloss:0.272987\ttest-mlogloss:0.326573\n",
      "[420]\ttrain-mlogloss:0.270149\ttest-mlogloss:0.326521\n",
      "[440]\ttrain-mlogloss:0.267282\ttest-mlogloss:0.326194\n",
      "[460]\ttrain-mlogloss:0.264493\ttest-mlogloss:0.325874\n",
      "[480]\ttrain-mlogloss:0.261741\ttest-mlogloss:0.325661\n",
      "[500]\ttrain-mlogloss:0.259117\ttest-mlogloss:0.325601\n",
      "[520]\ttrain-mlogloss:0.256464\ttest-mlogloss:0.32546\n",
      "[540]\ttrain-mlogloss:0.253921\ttest-mlogloss:0.325523\n",
      "[560]\ttrain-mlogloss:0.251535\ttest-mlogloss:0.325404\n",
      "[580]\ttrain-mlogloss:0.249065\ttest-mlogloss:0.325381\n",
      "[600]\ttrain-mlogloss:0.24658\ttest-mlogloss:0.325551\n",
      "[620]\ttrain-mlogloss:0.244262\ttest-mlogloss:0.325298\n",
      "[640]\ttrain-mlogloss:0.242039\ttest-mlogloss:0.325413\n",
      "[660]\ttrain-mlogloss:0.239908\ttest-mlogloss:0.3254\n",
      "[680]\ttrain-mlogloss:0.237705\ttest-mlogloss:0.325191\n",
      "[700]\ttrain-mlogloss:0.235402\ttest-mlogloss:0.325117\n",
      "[720]\ttrain-mlogloss:0.233305\ttest-mlogloss:0.325023\n",
      "[740]\ttrain-mlogloss:0.231207\ttest-mlogloss:0.325338\n",
      "[760]\ttrain-mlogloss:0.229315\ttest-mlogloss:0.325316\n",
      "[780]\ttrain-mlogloss:0.227224\ttest-mlogloss:0.325313\n",
      "[800]\ttrain-mlogloss:0.225141\ttest-mlogloss:0.325291\n",
      "[820]\ttrain-mlogloss:0.223034\ttest-mlogloss:0.325493\n",
      "[840]\ttrain-mlogloss:0.2211\ttest-mlogloss:0.325923\n",
      "[860]\ttrain-mlogloss:0.219137\ttest-mlogloss:0.325806\n",
      "[880]\ttrain-mlogloss:0.217356\ttest-mlogloss:0.325747\n",
      "[900]\ttrain-mlogloss:0.2155\ttest-mlogloss:0.325527\n",
      "[920]\ttrain-mlogloss:0.213481\ttest-mlogloss:0.325854\n",
      "Stopping. Best iteration:\n",
      "[728]\ttrain-mlogloss:0.232434\ttest-mlogloss:0.324975\n",
      "\n",
      "[0]\ttrain-mlogloss:1.01655\ttest-mlogloss:1.01567\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-mlogloss:0.475053\ttest-mlogloss:0.469067\n",
      "[40]\ttrain-mlogloss:0.394581\ttest-mlogloss:0.389679\n",
      "[60]\ttrain-mlogloss:0.369721\ttest-mlogloss:0.369388\n",
      "[80]\ttrain-mlogloss:0.355609\ttest-mlogloss:0.358833\n",
      "[100]\ttrain-mlogloss:0.344605\ttest-mlogloss:0.350566\n",
      "[120]\ttrain-mlogloss:0.335896\ttest-mlogloss:0.345191\n",
      "[140]\ttrain-mlogloss:0.328192\ttest-mlogloss:0.34068\n",
      "[160]\ttrain-mlogloss:0.321803\ttest-mlogloss:0.337498\n",
      "[180]\ttrain-mlogloss:0.315934\ttest-mlogloss:0.334545\n",
      "[200]\ttrain-mlogloss:0.310825\ttest-mlogloss:0.332557\n",
      "[220]\ttrain-mlogloss:0.30613\ttest-mlogloss:0.331239\n",
      "[240]\ttrain-mlogloss:0.301764\ttest-mlogloss:0.329641\n",
      "[260]\ttrain-mlogloss:0.297551\ttest-mlogloss:0.328884\n",
      "[280]\ttrain-mlogloss:0.293657\ttest-mlogloss:0.327736\n",
      "[300]\ttrain-mlogloss:0.289975\ttest-mlogloss:0.326925\n",
      "[320]\ttrain-mlogloss:0.286593\ttest-mlogloss:0.326492\n",
      "[340]\ttrain-mlogloss:0.283179\ttest-mlogloss:0.325567\n",
      "[360]\ttrain-mlogloss:0.280148\ttest-mlogloss:0.325212\n",
      "[380]\ttrain-mlogloss:0.277139\ttest-mlogloss:0.324746\n",
      "[400]\ttrain-mlogloss:0.274133\ttest-mlogloss:0.324751\n",
      "[420]\ttrain-mlogloss:0.271231\ttest-mlogloss:0.324599\n",
      "[440]\ttrain-mlogloss:0.268429\ttest-mlogloss:0.324367\n",
      "[460]\ttrain-mlogloss:0.26555\ttest-mlogloss:0.32399\n",
      "[480]\ttrain-mlogloss:0.262927\ttest-mlogloss:0.323858\n",
      "[500]\ttrain-mlogloss:0.260303\ttest-mlogloss:0.323595\n",
      "[520]\ttrain-mlogloss:0.257837\ttest-mlogloss:0.323507\n",
      "[540]\ttrain-mlogloss:0.255292\ttest-mlogloss:0.323477\n",
      "[560]\ttrain-mlogloss:0.252872\ttest-mlogloss:0.323335\n",
      "[580]\ttrain-mlogloss:0.250379\ttest-mlogloss:0.323188\n",
      "[600]\ttrain-mlogloss:0.247918\ttest-mlogloss:0.322983\n",
      "[620]\ttrain-mlogloss:0.245457\ttest-mlogloss:0.323245\n",
      "[640]\ttrain-mlogloss:0.243155\ttest-mlogloss:0.323157\n",
      "[660]\ttrain-mlogloss:0.240869\ttest-mlogloss:0.323256\n",
      "[680]\ttrain-mlogloss:0.238612\ttest-mlogloss:0.323477\n",
      "[700]\ttrain-mlogloss:0.236507\ttest-mlogloss:0.323862\n",
      "[720]\ttrain-mlogloss:0.234317\ttest-mlogloss:0.32377\n",
      "[740]\ttrain-mlogloss:0.232304\ttest-mlogloss:0.323539\n",
      "[760]\ttrain-mlogloss:0.230194\ttest-mlogloss:0.324004\n",
      "[780]\ttrain-mlogloss:0.228118\ttest-mlogloss:0.324127\n",
      "Stopping. Best iteration:\n",
      "[592]\ttrain-mlogloss:0.248885\ttest-mlogloss:0.322864\n",
      "\n",
      "[0]\ttrain-mlogloss:1.01608\ttest-mlogloss:1.01664\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-mlogloss:0.471914\ttest-mlogloss:0.476546\n",
      "[40]\ttrain-mlogloss:0.392551\ttest-mlogloss:0.400066\n",
      "[60]\ttrain-mlogloss:0.367397\ttest-mlogloss:0.378551\n",
      "[80]\ttrain-mlogloss:0.352455\ttest-mlogloss:0.367781\n",
      "[100]\ttrain-mlogloss:0.341188\ttest-mlogloss:0.360506\n",
      "[120]\ttrain-mlogloss:0.332462\ttest-mlogloss:0.355349\n",
      "[140]\ttrain-mlogloss:0.325154\ttest-mlogloss:0.351854\n",
      "[160]\ttrain-mlogloss:0.318886\ttest-mlogloss:0.348673\n",
      "[180]\ttrain-mlogloss:0.313191\ttest-mlogloss:0.346282\n",
      "[200]\ttrain-mlogloss:0.307798\ttest-mlogloss:0.344038\n",
      "[220]\ttrain-mlogloss:0.303169\ttest-mlogloss:0.342574\n",
      "[240]\ttrain-mlogloss:0.29911\ttest-mlogloss:0.341237\n",
      "[260]\ttrain-mlogloss:0.29512\ttest-mlogloss:0.339981\n",
      "[280]\ttrain-mlogloss:0.291401\ttest-mlogloss:0.33916\n",
      "[300]\ttrain-mlogloss:0.287902\ttest-mlogloss:0.338366\n",
      "[320]\ttrain-mlogloss:0.284332\ttest-mlogloss:0.337971\n",
      "[340]\ttrain-mlogloss:0.281124\ttest-mlogloss:0.337084\n",
      "[360]\ttrain-mlogloss:0.278093\ttest-mlogloss:0.335925\n",
      "[380]\ttrain-mlogloss:0.27474\ttest-mlogloss:0.335307\n",
      "[400]\ttrain-mlogloss:0.271842\ttest-mlogloss:0.334786\n",
      "[420]\ttrain-mlogloss:0.268907\ttest-mlogloss:0.334503\n",
      "[440]\ttrain-mlogloss:0.266131\ttest-mlogloss:0.334094\n",
      "[460]\ttrain-mlogloss:0.263465\ttest-mlogloss:0.333579\n",
      "[480]\ttrain-mlogloss:0.26084\ttest-mlogloss:0.333577\n",
      "[500]\ttrain-mlogloss:0.258352\ttest-mlogloss:0.333371\n",
      "[520]\ttrain-mlogloss:0.255737\ttest-mlogloss:0.332933\n",
      "[540]\ttrain-mlogloss:0.253159\ttest-mlogloss:0.333166\n",
      "[560]\ttrain-mlogloss:0.250755\ttest-mlogloss:0.33313\n",
      "[580]\ttrain-mlogloss:0.248442\ttest-mlogloss:0.332359\n",
      "[600]\ttrain-mlogloss:0.245886\ttest-mlogloss:0.331846\n",
      "[620]\ttrain-mlogloss:0.243646\ttest-mlogloss:0.331667\n",
      "[640]\ttrain-mlogloss:0.241344\ttest-mlogloss:0.331524\n",
      "[660]\ttrain-mlogloss:0.239154\ttest-mlogloss:0.331386\n",
      "[680]\ttrain-mlogloss:0.236858\ttest-mlogloss:0.331248\n",
      "[700]\ttrain-mlogloss:0.234672\ttest-mlogloss:0.331124\n",
      "[720]\ttrain-mlogloss:0.232459\ttest-mlogloss:0.33083\n",
      "[740]\ttrain-mlogloss:0.230461\ttest-mlogloss:0.33087\n",
      "[760]\ttrain-mlogloss:0.228428\ttest-mlogloss:0.330905\n",
      "[780]\ttrain-mlogloss:0.226406\ttest-mlogloss:0.331143\n",
      "[800]\ttrain-mlogloss:0.22436\ttest-mlogloss:0.330805\n",
      "[820]\ttrain-mlogloss:0.222469\ttest-mlogloss:0.330654\n",
      "[840]\ttrain-mlogloss:0.220575\ttest-mlogloss:0.330767\n",
      "[860]\ttrain-mlogloss:0.218629\ttest-mlogloss:0.330748\n",
      "[880]\ttrain-mlogloss:0.216839\ttest-mlogloss:0.331085\n",
      "[900]\ttrain-mlogloss:0.214894\ttest-mlogloss:0.33129\n",
      "[920]\ttrain-mlogloss:0.2129\ttest-mlogloss:0.331221\n",
      "[940]\ttrain-mlogloss:0.210992\ttest-mlogloss:0.331264\n",
      "[960]\ttrain-mlogloss:0.209059\ttest-mlogloss:0.331277\n",
      "[980]\ttrain-mlogloss:0.207312\ttest-mlogloss:0.331568\n",
      "[1000]\ttrain-mlogloss:0.205539\ttest-mlogloss:0.331465\n",
      "Stopping. Best iteration:\n",
      "[814]\ttrain-mlogloss:0.223042\ttest-mlogloss:0.330547\n",
      "\n",
      "[0]\ttrain-mlogloss:1.03858\ttest-mlogloss:1.03923\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-mlogloss:0.465877\ttest-mlogloss:0.4697\n",
      "[40]\ttrain-mlogloss:0.389875\ttest-mlogloss:0.396872\n",
      "[60]\ttrain-mlogloss:0.366635\ttest-mlogloss:0.377581\n",
      "[80]\ttrain-mlogloss:0.35207\ttest-mlogloss:0.367902\n",
      "[100]\ttrain-mlogloss:0.341029\ttest-mlogloss:0.361298\n",
      "[120]\ttrain-mlogloss:0.332186\ttest-mlogloss:0.35579\n",
      "[140]\ttrain-mlogloss:0.324513\ttest-mlogloss:0.352316\n",
      "[160]\ttrain-mlogloss:0.318236\ttest-mlogloss:0.349291\n",
      "[180]\ttrain-mlogloss:0.312591\ttest-mlogloss:0.347301\n",
      "[200]\ttrain-mlogloss:0.307404\ttest-mlogloss:0.34561\n",
      "[220]\ttrain-mlogloss:0.302741\ttest-mlogloss:0.344251\n",
      "[240]\ttrain-mlogloss:0.298306\ttest-mlogloss:0.343149\n",
      "[260]\ttrain-mlogloss:0.294296\ttest-mlogloss:0.341976\n",
      "[280]\ttrain-mlogloss:0.290316\ttest-mlogloss:0.341775\n",
      "[300]\ttrain-mlogloss:0.286636\ttest-mlogloss:0.340936\n",
      "[320]\ttrain-mlogloss:0.28316\ttest-mlogloss:0.340356\n",
      "[340]\ttrain-mlogloss:0.279761\ttest-mlogloss:0.339383\n",
      "[360]\ttrain-mlogloss:0.27671\ttest-mlogloss:0.338868\n",
      "[380]\ttrain-mlogloss:0.273679\ttest-mlogloss:0.33812\n",
      "[400]\ttrain-mlogloss:0.270519\ttest-mlogloss:0.337661\n",
      "[420]\ttrain-mlogloss:0.267747\ttest-mlogloss:0.337966\n",
      "[440]\ttrain-mlogloss:0.265069\ttest-mlogloss:0.337773\n",
      "[460]\ttrain-mlogloss:0.262377\ttest-mlogloss:0.337446\n",
      "[480]\ttrain-mlogloss:0.259637\ttest-mlogloss:0.337023\n",
      "[500]\ttrain-mlogloss:0.257152\ttest-mlogloss:0.336849\n",
      "[520]\ttrain-mlogloss:0.254556\ttest-mlogloss:0.336664\n",
      "[540]\ttrain-mlogloss:0.252098\ttest-mlogloss:0.336606\n",
      "[560]\ttrain-mlogloss:0.24965\ttest-mlogloss:0.336571\n",
      "[580]\ttrain-mlogloss:0.24722\ttest-mlogloss:0.336629\n",
      "[600]\ttrain-mlogloss:0.244776\ttest-mlogloss:0.336596\n",
      "[620]\ttrain-mlogloss:0.242415\ttest-mlogloss:0.337001\n",
      "[640]\ttrain-mlogloss:0.240191\ttest-mlogloss:0.336937\n",
      "[660]\ttrain-mlogloss:0.238033\ttest-mlogloss:0.336988\n",
      "[680]\ttrain-mlogloss:0.235882\ttest-mlogloss:0.336874\n",
      "[700]\ttrain-mlogloss:0.233643\ttest-mlogloss:0.336491\n",
      "[720]\ttrain-mlogloss:0.231441\ttest-mlogloss:0.336371\n",
      "[740]\ttrain-mlogloss:0.229498\ttest-mlogloss:0.336828\n",
      "[760]\ttrain-mlogloss:0.227356\ttest-mlogloss:0.337288\n",
      "[780]\ttrain-mlogloss:0.225308\ttest-mlogloss:0.337122\n",
      "[800]\ttrain-mlogloss:0.223344\ttest-mlogloss:0.337135\n",
      "[820]\ttrain-mlogloss:0.221282\ttest-mlogloss:0.337386\n",
      "[840]\ttrain-mlogloss:0.219265\ttest-mlogloss:0.337313\n",
      "[860]\ttrain-mlogloss:0.217397\ttest-mlogloss:0.337263\n",
      "[880]\ttrain-mlogloss:0.215457\ttest-mlogloss:0.337733\n",
      "[900]\ttrain-mlogloss:0.213493\ttest-mlogloss:0.337375\n",
      "Stopping. Best iteration:\n",
      "[716]\ttrain-mlogloss:0.231899\ttest-mlogloss:0.336314\n",
      "\n",
      "cv scores :  [0.3566120052911848, 0.32497459884425933, 0.32286343176809196, 0.3305468994940551, 0.33631433048336606]\n"
     ]
    }
   ],
   "source": [
    "cols_to_drop = ['id', 'text']\n",
    "train_X = train.drop(cols_to_drop+['author'], axis=1)\n",
    "test_X = test.drop(cols_to_drop, axis=1)\n",
    "\n",
    "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 3])\n",
    "for dev_index, val_index in kf.split(train_X):\n",
    "    dev_X, val_X = train_X.loc[dev_index], train_X.loc[val_index]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "    pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, test_X, seed_val=42, colsample=0.6)\n",
    "    pred_full_test = pred_full_test + pred_test_y\n",
    "    pred_train[val_index,:] = pred_val_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "print(\"cv scores : \", cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(pred_full_test)\n",
    "sub.columns = ['EAP', 'HPL', 'MWS']\n",
    "sub.insert(0, 'id', test_id)\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
